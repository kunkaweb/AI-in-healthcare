{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification of Chest and Abdominal X-rays.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ESTS1UtZsyZg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classification of Chest and Abdominal X-rays"
      ]
    },
    {
      "metadata": {
        "id": "FH7q7NEXblGS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code Source: Lakhani, P., Gray, D.L., Pett, C.R. et al. J Digit Imaging (2018) 31: 283. https://doi.org/10.1007/s10278-018-0079-6\n",
        "\n",
        "The code to download and prepare dataset had been modified form the original source code."
      ]
    },
    {
      "metadata": {
        "id": "Pae1ZD1NXf8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load requirements for the Keras library\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qzIZnc5lElQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /content/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgmldJ9uk9eZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!wget https://github.com/kunkaweb/Hello_World_Deep_Learning/blob/master/Open_I_abd_vs_CXRs.zip?raw=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dx2ZtkdnlSDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIIYcR7sluND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unzip\n",
        "!unzip /content/Open_I_abd_vs_CXRs.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lIJNodaYB8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dimensions of our images\n",
        "img_width, img_height = 299, 299\n",
        "\n",
        "# directory and image information\n",
        "train_data_dir = 'Open_I_abd_vs_CXRs/TRAIN/'\n",
        "validation_data_dir = 'Open_I_abd_vs_CXRs/VAL/'\n",
        "\n",
        "# epochs = number of passes of through training data\n",
        "# batch_size = number of images processes at the same time\n",
        "train_samples = 65\n",
        "validation_samples = 10\n",
        "epochs = 20\n",
        "batch_size = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlQY0FlzbvLn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the Inception V3 network, use pretrained weights from ImgaeNet\n",
        "# remove top funnly connected layers by imclude_top=False\n",
        "\n",
        "base_model = applications.InceptionV3(weights='imagenet', include_top=False,\n",
        "                                     input_shape=(img_width, img_height,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uonB6Pq-cXxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build a classifier model to put on top of the convolutional model\n",
        "# This consists of a global average pooling layer and a fully connected layer with 256 nodes\n",
        "# Then apply dropout and signoid activation\n",
        "\n",
        "model_top = Sequential()\n",
        "model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:],\n",
        "                                    data_format=None)),\n",
        "model_top.add(Dense(256, activation='relu'))\n",
        "model_top.add(Dropout(0.5))\n",
        "model_top.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n",
        "\n",
        "# Compile model using Adam optimizer with common values and binary cross entropy loss\n",
        "# USe low learning rate (lr) for transfer learning\n",
        "model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twuwaLeNdsFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Some on-the-fly augmentation options\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255, # Rescale pixel values to 0-1 to aid CNN processing\n",
        "  shear_range = 0.2, # 0-1 range for shearing\n",
        "  zoom_range = 0.2, # 0-1 range for zoom\n",
        "  rotation_range = 20, # 0.180 range, degrees of rotation\n",
        "  width_shift_range = 0.2, # 0-1 range horizontal translation\n",
        "  height_shift_range = 0.2, # 0-1 range vertical translation\n",
        "  horizontal_flip = True # set True or false\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "  rescale=1./255 # Rescale pixel values to 0-1 to aid CNN processing\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zo0bcIskhBPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Directory, image size, batch size already specied above\n",
        "# Class mode is set to 'binary' for a 2-class problem\n",
        "# Generator randomly shuffles and presents images in batches to the network\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OIGyQ4xkdaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fine-tune the pretrained Inception V3 model using the data generator\n",
        "# Specify steps per epoch (number of samples/batch_size)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_samples//batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AHoYX0Yroba3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import matplotlib library, and plot training curve\n",
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['acc'],'orange', label='Training accuracy')\n",
        "plt.plot(history.history['val_acc'],'blue', label='Validation accuracy')\n",
        "plt.plot(history.history['loss'],'red', label='Training loss')\n",
        "plt.plot(history.history['val_loss'],'green', label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycWxF-MvpI1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy and keras preprocessing libraries\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# load, resize, and display test images\n",
        "img_path = 'Open_I_abd_vs_CXRs/TEST/abd2.png'\n",
        "img_path2 = 'Open_I_abd_vs_CXRs/TEST/chest2.png'\n",
        "img = image.load_img(img_path, target_size=(img_width, img_height))\n",
        "img2 = image.load_img(img_path2, target_size=(img_width, img_height))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# convert image to numpy array, so Keras can render a prediction\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# expand array from 3 dimensions (height, width, channels) to 4 dimensions (batch size, height, width, channels)\n",
        "# rescale pixel values to 0-1\n",
        "x = np.expand_dims(img, axis=0) * 1./255\n",
        "\n",
        "# get prediction on test image\n",
        "score = model.predict(x)\n",
        "print('Predicted:', score, 'Chest X-ray' if score < 0.5 else 'Abd X-ray')\n",
        "\n",
        "# display and render a prediction for the 2nd image\n",
        "plt.imshow(img2)\n",
        "plt.show()\n",
        "img2 = image.img_to_array(img2)\n",
        "x = np.expand_dims(img2, axis=0) * 1./255\n",
        "score = model.predict(x)\n",
        "print('Predicted:', score, 'Chest X-ray' if score < 0.5 else 'Abd X-ray')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
